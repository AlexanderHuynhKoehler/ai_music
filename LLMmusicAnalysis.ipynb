{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "679a042b-6f08-4fa6-a74f-9e8386a82f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/koehler.ale/miniconda3/envs/llm-music/lib/python3.10/site-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: invent1.mid: 341 intervals extracted\n",
      "Success: invent5.mid: 529 intervals extracted\n",
      "Success: invent6.mid: 885 intervals extracted\n",
      "Success: invent7.mid: 384 intervals extracted\n",
      "Success: invent8.mid: 372 intervals extracted\n",
      "Success: invent9.mid: 401 intervals extracted\n",
      "\n",
      "BACH CORPUS SUMMARY:\n",
      "   Processed files: 6\n",
      "   Total intervals: 2912\n",
      "Saved Bach interval corpus to: bach_reference_intervals.json\n",
      "EXTRACTING LLM CORPUS INTERVALS\n",
      "==================================================\n",
      "Success: compose_a_melody_in_000.mid: 31 intervals extracted\n",
      "Success: compose_a_melody_in_001.mid: 37 intervals extracted\n",
      "Success: compose_a_melody_in_002.mid: 35 intervals extracted\n",
      "Success: compose_a_melody_in_003.mid: 34 intervals extracted\n",
      "Success: compose_a_melody_in_004.mid: 35 intervals extracted\n",
      "Success: compose_a_melody_in_005.mid: 35 intervals extracted\n",
      "Success: compose_a_melody_in_006.mid: 37 intervals extracted\n",
      "Success: compose_a_melody_in_007.mid: 33 intervals extracted\n",
      "Success: compose_a_melody_in_008.mid: 37 intervals extracted\n",
      "Success: compose_a_melody_in_009.mid: 33 intervals extracted\n",
      "Success: compose_a_melody_in_010.mid: 43 intervals extracted\n",
      "Success: compose_a_melody_in_011.mid: 36 intervals extracted\n",
      "Success: compose_a_melody_in_012.mid: 41 intervals extracted\n",
      "Success: compose_a_melody_in_013.mid: 34 intervals extracted\n",
      "Success: compose_a_melody_in_014.mid: 31 intervals extracted\n",
      "Success: compose_a_melody_in_015.mid: 34 intervals extracted\n",
      "Success: compose_a_melody_in_016.mid: 38 intervals extracted\n",
      "Success: compose_a_melody_in_017.mid: 39 intervals extracted\n",
      "Success: compose_a_melody_in_018.mid: 31 intervals extracted\n",
      "Success: compose_a_melody_in_019.mid: 37 intervals extracted\n",
      "Success: compose_a_melody_in_020.mid: 36 intervals extracted\n",
      "Success: compose_a_melody_in_021.mid: 33 intervals extracted\n",
      "Success: compose_a_melody_in_022.mid: 37 intervals extracted\n",
      "Success: compose_a_melody_in_023.mid: 36 intervals extracted\n",
      "Success: compose_a_melody_in_024.mid: 37 intervals extracted\n",
      "Success: compose_a_melody_in_025.mid: 35 intervals extracted\n",
      "Success: compose_a_melody_in_026.mid: 29 intervals extracted\n",
      "Success: compose_a_melody_in_027.mid: 34 intervals extracted\n",
      "Success: compose_a_melody_in_028.mid: 31 intervals extracted\n",
      "Success: compose_a_melody_in_029.mid: 25 intervals extracted\n",
      "Success: compose_a_melody_in_030.mid: 35 intervals extracted\n",
      "Success: compose_a_melody_in_031.mid: 37 intervals extracted\n",
      "Success: compose_a_melody_in_032.mid: 37 intervals extracted\n",
      "Success: compose_a_melody_in_033.mid: 34 intervals extracted\n",
      "Success: compose_a_melody_in_034.mid: 31 intervals extracted\n",
      "Success: compose_a_melody_in_035.mid: 23 intervals extracted\n",
      "Success: compose_a_melody_in_036.mid: 37 intervals extracted\n",
      "Success: compose_a_melody_in_037.mid: 31 intervals extracted\n",
      "Success: compose_a_melody_in_038.mid: 36 intervals extracted\n",
      "Success: compose_a_melody_in_039.mid: 39 intervals extracted\n",
      "Success: compose_a_melody_in_040.mid: 30 intervals extracted\n",
      "Success: compose_a_melody_in_041.mid: 41 intervals extracted\n",
      "Success: compose_a_melody_in_042.mid: 36 intervals extracted\n",
      "Success: compose_a_melody_in_043.mid: 35 intervals extracted\n",
      "Success: compose_a_melody_in_044.mid: 31 intervals extracted\n",
      "Success: compose_a_melody_in_045.mid: 25 intervals extracted\n",
      "Success: compose_a_melody_in_046.mid: 29 intervals extracted\n",
      "Success: compose_a_melody_in_047.mid: 35 intervals extracted\n",
      "Success: compose_a_melody_in_048.mid: 28 intervals extracted\n",
      "Success: compose_a_melody_in_049.mid: 35 intervals extracted\n",
      "Success: compose_a_melody_in_050.mid: 21 intervals extracted\n",
      "Success: compose_a_melody_in_051.mid: 23 intervals extracted\n",
      "Success: compose_a_melody_in_052.mid: 37 intervals extracted\n",
      "Success: compose_a_melody_in_053.mid: 39 intervals extracted\n",
      "Success: compose_a_melody_in_054.mid: 23 intervals extracted\n",
      "Success: compose_a_melody_in_055.mid: 35 intervals extracted\n",
      "Success: compose_a_melody_in_056.mid: 41 intervals extracted\n",
      "Success: compose_a_melody_in_057.mid: 40 intervals extracted\n",
      "Success: compose_a_melody_in_058.mid: 39 intervals extracted\n",
      "Success: compose_a_melody_in_059.mid: 25 intervals extracted\n",
      "Success: compose_a_melody_in_060.mid: 33 intervals extracted\n",
      "\n",
      "LLM CORPUS SUMMARY:\n",
      "   Processed files: 61\n",
      "   Total intervals: 2065\n",
      "Saved LLM interval corpus to: llm_bach_intervals.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import note_seq\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "def extract_bach_melodies(bach_midi_folder):\n",
    "\n",
    "    bach_intervals = []\n",
    "    processed_files = 0\n",
    "    \n",
    "    midi_files = [f for f in os.listdir(bach_midi_folder) if f.endswith('.mid')]\n",
    "    \n",
    "    for filename in midi_files:\n",
    "        filepath = os.path.join(bach_midi_folder, filename)\n",
    "        \n",
    "        try:\n",
    "            sequence = note_seq.midi_file_to_note_sequence(filepath)\n",
    "            \n",
    "            if len(sequence.notes) == 0:\n",
    "                print(f\"Warning: {filename}: No notes found\")\n",
    "                continue\n",
    "            \n",
    "            # Extract melody line\n",
    "            melody_intervals = extract_melody_line(sequence)\n",
    "            \n",
    "            if melody_intervals:\n",
    "                bach_intervals.extend(melody_intervals)\n",
    "                processed_files += 1\n",
    "                print(f\"Success: {filename}: {len(melody_intervals)} intervals extracted\")\n",
    "            else:\n",
    "                print(f\"Warning: {filename}: No melody extracted\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error: {filename}: Error - {e}\")\n",
    "    \n",
    "    print(f\"\\nBACH CORPUS SUMMARY:\")\n",
    "    print(f\"   Processed files: {processed_files}\")\n",
    "    print(f\"   Total intervals: {len(bach_intervals)}\")\n",
    "    \n",
    "    # Save Bach corpus to CURRENT DIRECTORY\n",
    "    output_path = 'bach_reference_intervals.json'\n",
    "    with open(output_path, 'w') as f:\n",
    "        json.dump(bach_intervals, f)\n",
    "    \n",
    "    print(f\"Saved Bach interval corpus to: {output_path}\")\n",
    "    return bach_intervals\n",
    "\n",
    "def extract_llm_corpus_intervals(llm_midi_folder):\n",
    "    \"\"\"\n",
    "    Extract interval sequences from your LLM-generated MIDI files.\n",
    "    Saves JSON to current directory.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"EXTRACTING LLM CORPUS INTERVALS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    llm_intervals = []\n",
    "    processed_files = 0\n",
    "    \n",
    "    midi_files = [f for f in os.listdir(llm_midi_folder) if f.endswith('.mid')]\n",
    "    \n",
    "    for filename in midi_files:\n",
    "        filepath = os.path.join(llm_midi_folder, filename)\n",
    "        \n",
    "        try:\n",
    "            # Load MIDI\n",
    "            sequence = note_seq.midi_file_to_note_sequence(filepath)\n",
    "            \n",
    "            if len(sequence.notes) == 0:\n",
    "                print(f\"Warning: {filename}: No notes found\")\n",
    "                continue\n",
    "            \n",
    "            # Extract intervals (same as Bach method)\n",
    "            notes = sorted(sequence.notes, key=lambda n: n.start_time)\n",
    "            pitches = [note.pitch for note in notes]\n",
    "            \n",
    "            if len(pitches) < 2:\n",
    "                continue\n",
    "                \n",
    "            # Convert to intervals\n",
    "            intervals = []\n",
    "            for i in range(1, len(pitches)):\n",
    "                interval = pitches[i] - pitches[i-1]\n",
    "                intervals.append(interval)\n",
    "            \n",
    "            llm_intervals.extend(intervals)\n",
    "            processed_files += 1\n",
    "            print(f\"Success: {filename}: {len(intervals)} intervals extracted\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error: {filename}: Error - {e}\")\n",
    "    \n",
    "    print(f\"\\nLLM CORPUS SUMMARY:\")\n",
    "    print(f\"   Processed files: {processed_files}\")\n",
    "    print(f\"   Total intervals: {len(llm_intervals)}\")\n",
    "    \n",
    "    # Save LLM corpus to CURRENT DIRECTORY\n",
    "    output_path = 'llm_bach_intervals.json'\n",
    "    with open(output_path, 'w') as f:\n",
    "        json.dump(llm_intervals, f)\n",
    "    \n",
    "    print(f\"Saved LLM interval corpus to: {output_path}\")\n",
    "    return llm_intervals\n",
    "\n",
    "def extract_melody_line(sequence):\n",
    "    \"\"\"Extract the primary melody line from a MIDI sequence.\"\"\"\n",
    "    \n",
    "    if len(sequence.notes) == 0:\n",
    "        return []\n",
    "    \n",
    "    # Sort notes by start time\n",
    "    notes = sorted(sequence.notes, key=lambda n: n.start_time)\n",
    "    \n",
    "    # Method 1: For solo works, use all notes\n",
    "    if len(set(note.instrument for note in notes)) == 1:\n",
    "        # Single instrument - use all notes\n",
    "        pitches = [note.pitch for note in notes]\n",
    "    else:\n",
    "        # Method 2: For polyphonic works, extract highest voice\n",
    "        # Group notes by time windows and take highest pitch\n",
    "        pitches = extract_soprano_voice(notes)\n",
    "    \n",
    "    # Convert to intervals\n",
    "    if len(pitches) < 2:\n",
    "        return []\n",
    "    \n",
    "    intervals = []\n",
    "    for i in range(1, len(pitches)):\n",
    "        interval = pitches[i] - pitches[i-1]\n",
    "        intervals.append(interval)\n",
    "    \n",
    "    return intervals\n",
    "\n",
    "def extract_soprano_voice(notes):\n",
    "    \"\"\"Extract the soprano (highest) voice from polyphonic MIDI.\"\"\"\n",
    "    \n",
    "    # Group notes by time windows (handle simultaneity)\n",
    "    time_windows = {}\n",
    "    window_size = 0.1  # 100ms window\n",
    "    \n",
    "    for note in notes:\n",
    "        window = round(note.start_time / window_size) * window_size\n",
    "        if window not in time_windows:\n",
    "            time_windows[window] = []\n",
    "        time_windows[window].append(note)\n",
    "    \n",
    "    # Extract highest pitch from each time window\n",
    "    soprano_pitches = []\n",
    "    for time_point in sorted(time_windows.keys()):\n",
    "        notes_at_time = time_windows[time_point]\n",
    "        highest_note = max(notes_at_time, key=lambda n: n.pitch)\n",
    "        soprano_pitches.append(highest_note.pitch)\n",
    "    \n",
    "    return soprano_pitches\n",
    "\n",
    "\n",
    "bach_intervals = extract_bach_melodies('bach_reference/')\n",
    "llm_intervals = extract_llm_corpus_intervals('Generated_corpus/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e06b0d68-8127-485e-bdba-e310c6e434b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N-GRAM STYLE AUTHENTICITY ANALYSIS (n=3)\n",
      "============================================================\n",
      "Loading corpora...\n",
      "   Bach corpus: 2912 intervals\n",
      "   LLM corpus: 2065 intervals\n",
      "\n",
      "Generating 3-grams...\n",
      "   Bach 3-grams: 2910\n",
      "   LLM 3-grams: 2063\n",
      "\n",
      "AUTHENTICITY ANALYSIS\n",
      "==============================\n",
      "LLM Pattern Authenticity: 13.3%\n",
      "   (81 of 609 LLM patterns found in Bach)\n",
      "Bach Pattern Coverage: 6.0%\n",
      "   (81 of 1346 Bach patterns reproduced)\n",
      "\n",
      "MOST BACH-LIKE LLM PATTERNS:\n",
      "    1. -2 -2 -1        | Bach:  47 | LLM:  56\n",
      "    2. -2 -1 -2        | Bach:  39 | LLM:  37\n",
      "    3. -2 -2 +2        | Bach:  15 | LLM:  10\n",
      "    4. -1 -2 -2        | Bach:  45 | LLM:  10\n",
      "    5. +2 -2 -2        | Bach:  12 | LLM:   8\n",
      "    6. -2 -2 -2        | Bach:   8 | LLM:  39\n",
      "    7. -2 -1 +3        | Bach:   7 | LLM:  30\n",
      "    8. -2 +4 -2        | Bach:   9 | LLM:   6\n",
      "    9. -2 +2 -3        | Bach:  18 | LLM:   5\n",
      "   10. -1 -2 +3        | Bach:   8 | LLM:   5\n",
      "\n",
      "LEAST BACH-LIKE LLM PATTERNS:\n",
      "   1. +4 +3 +4        | Used 94 times (not in Bach)\n",
      "   2. +4 +1 +4        | Used 34 times (not in Bach)\n",
      "   3. +1 +4 +3        | Used 33 times (not in Bach)\n",
      "   4. +3 +4 -4        | Used 26 times (not in Bach)\n",
      "   5. +4 -11 +4       | Used 22 times (not in Bach)\n",
      "\n",
      "OVERALL BACH AUTHENTICITY SCORE\n",
      "===================================\n",
      "Composite Score: 9.7/100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'pattern_overlap': 13.30049261083744,\n",
       " 'bach_coverage': 6.017830609212481,\n",
       " 'overall_score': 9.65916161002496,\n",
       " 'shared_patterns': 81,\n",
       " 'bach_unique_patterns': 1265,\n",
       " 'llm_unique_patterns': 528,\n",
       " 'most_authentic': [((-2, -2, -1), 47, 56, 47),\n",
       "  ((-2, -1, -2), 39, 37, 37),\n",
       "  ((-2, -2, 2), 15, 10, 10),\n",
       "  ((-1, -2, -2), 45, 10, 10),\n",
       "  ((2, -2, -2), 12, 8, 8),\n",
       "  ((-2, -2, -2), 8, 39, 8),\n",
       "  ((-2, -1, 3), 7, 30, 7),\n",
       "  ((-2, 4, -2), 9, 6, 6),\n",
       "  ((-2, 2, -3), 18, 5, 5),\n",
       "  ((-1, -2, 3), 8, 5, 5)],\n",
       " 'least_authentic': [((4, 3, 4), 94),\n",
       "  ((4, 1, 4), 34),\n",
       "  ((1, 4, 3), 33),\n",
       "  ((3, 4, -4), 26),\n",
       "  ((4, -11, 4), 22)]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter, defaultdict\n",
    "\n",
    "def generate_ngrams(interval_sequence, n=3):\n",
    "    \"\"\"Generate n-grams from interval sequence.\"\"\"\n",
    "    \n",
    "    if len(interval_sequence) < n:\n",
    "        return []\n",
    "    \n",
    "    ngrams = []\n",
    "    for i in range(len(interval_sequence) - n + 1):\n",
    "        ngram = tuple(interval_sequence[i:i+n])\n",
    "        ngrams.append(ngram)\n",
    "    \n",
    "    return ngrams\n",
    "\n",
    "def analyze_bach_vs_llm_ngrams(bach_json_file, llm_json_file, n=3):\n",
    "    \"\"\"\n",
    "    Compare Bach vs LLM melodic patterns using n-gram analysis.\n",
    "    \n",
    "    This is the core research function!\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"N-GRAM STYLE AUTHENTICITY ANALYSIS (n={n})\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Load both corpora\n",
    "    print(\"Loading corpora...\")\n",
    "    with open(bach_json_file, 'r') as f:\n",
    "        bach_intervals = json.load(f)\n",
    "    \n",
    "    with open(llm_json_file, 'r') as f:\n",
    "        llm_intervals = json.load(f)\n",
    "    \n",
    "    print(f\"   Bach corpus: {len(bach_intervals)} intervals\")\n",
    "    print(f\"   LLM corpus: {len(llm_intervals)} intervals\")\n",
    "    \n",
    "    # Generate n-grams\n",
    "    print(f\"\\nGenerating {n}-grams...\")\n",
    "    bach_ngrams = generate_ngrams(bach_intervals, n)\n",
    "    llm_ngrams = generate_ngrams(llm_intervals, n)\n",
    "    \n",
    "    print(f\"   Bach {n}-grams: {len(bach_ngrams)}\")\n",
    "    print(f\"   LLM {n}-grams: {len(llm_ngrams)}\")\n",
    "    \n",
    "    # Convert to frequency distributions\n",
    "    bach_freq = Counter(bach_ngrams)\n",
    "    llm_freq = Counter(llm_ngrams)\n",
    "    \n",
    "    # Calculate overlap\n",
    "    bach_patterns = set(bach_freq.keys())\n",
    "    llm_patterns = set(llm_freq.keys())\n",
    "    shared_patterns = bach_patterns.intersection(llm_patterns)\n",
    "    \n",
    "    # Authenticity metrics\n",
    "    pattern_overlap = len(shared_patterns) / len(llm_patterns) * 100 if llm_patterns else 0\n",
    "    bach_coverage = len(shared_patterns) / len(bach_patterns) * 100 if bach_patterns else 0\n",
    "    \n",
    "    print(f\"\\nAUTHENTICITY ANALYSIS\")\n",
    "    print(\"=\" * 30)\n",
    "    print(f\"LLM Pattern Authenticity: {pattern_overlap:.1f}%\")\n",
    "    print(f\"   ({len(shared_patterns)} of {len(llm_patterns)} LLM patterns found in Bach)\")\n",
    "    print(f\"Bach Pattern Coverage: {bach_coverage:.1f}%\")\n",
    "    print(f\"   ({len(shared_patterns)} of {len(bach_patterns)} Bach patterns reproduced)\")\n",
    "    \n",
    "    # Most authentic LLM patterns\n",
    "    print(f\"\\nMOST BACH-LIKE LLM PATTERNS:\")\n",
    "    authentic_patterns = []\n",
    "    for pattern in shared_patterns:\n",
    "        bach_count = bach_freq[pattern]\n",
    "        llm_count = llm_freq[pattern]\n",
    "        authenticity_score = min(bach_count, llm_count)  # How well matched\n",
    "        authentic_patterns.append((pattern, bach_count, llm_count, authenticity_score))\n",
    "    \n",
    "    # Sort by authenticity score\n",
    "    authentic_patterns.sort(key=lambda x: x[3], reverse=True)\n",
    "    \n",
    "    for i, (pattern, bach_count, llm_count, score) in enumerate(authentic_patterns[:10]):\n",
    "        interval_str = \" \".join([f\"{'+' if x >= 0 else ''}{x}\" for x in pattern])\n",
    "        print(f\"   {i+1:2d}. {interval_str:15} | Bach: {bach_count:3} | LLM: {llm_count:3}\")\n",
    "    \n",
    "    # Most un-Bach-like LLM patterns\n",
    "    print(f\"\\nLEAST BACH-LIKE LLM PATTERNS:\")\n",
    "    unauthentic_patterns = [(pattern, llm_freq[pattern]) for pattern in (llm_patterns - shared_patterns)]\n",
    "    unauthentic_patterns.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    for i, (pattern, count) in enumerate(unauthentic_patterns[:5]):\n",
    "        interval_str = \" \".join([f\"{'+' if x >= 0 else ''}{x}\" for x in pattern])\n",
    "        print(f\"   {i+1}. {interval_str:15} | Used {count} times (not in Bach)\")\n",
    "    \n",
    "    # Overall assessment\n",
    "    print(f\"\\nOVERALL BACH AUTHENTICITY SCORE\")\n",
    "    print(\"=\" * 35)\n",
    "    \n",
    "    overall_score = (pattern_overlap + bach_coverage) / 2\n",
    "    print(f\"Composite Score: {overall_score:.1f}/100\")\n",
    "    \n",
    "    return {\n",
    "        'pattern_overlap': pattern_overlap,\n",
    "        'bach_coverage': bach_coverage,\n",
    "        'overall_score': overall_score,\n",
    "        'shared_patterns': len(shared_patterns),\n",
    "        'bach_unique_patterns': len(bach_patterns - shared_patterns),\n",
    "        'llm_unique_patterns': len(llm_patterns - shared_patterns),\n",
    "        'most_authentic': authentic_patterns[:10],\n",
    "        'least_authentic': unauthentic_patterns[:5]\n",
    "    }\n",
    "\n",
    "def quick_comparison_test(bach_json, llm_json):\n",
    "    \"\"\"Quick test of different n-gram sizes.\"\"\"\n",
    "    \n",
    "    print(\"TESTING DIFFERENT N-GRAM SIZES\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    for n in [2, 3, 4, 5]:\n",
    "        print(f\"\\nTesting {n}-grams:\")\n",
    "        result = analyze_bach_vs_llm_ngrams(bach_json, llm_json, n=n)\n",
    "        print(f\"   Authenticity: {result['overall_score']:.1f}%\")\n",
    "\n",
    "analyze_bach_vs_llm_ngrams('bach_reference_intervals.json', 'llm_bach_intervals.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfd29bea-0064-476d-9a19-7a7b6e92b710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING COMPREHENSIVE MUSICAL ANALYSIS\n",
      "============================================================\n",
      "Using proper ratio-based similarity calculations\n",
      "Weighted scoring based on musical importance\n",
      "\n",
      "COMPREHENSIVE MUSICAL ANALYSIS\n",
      "============================================================\n",
      "Using ratio-based similarity calculations\n",
      "Bach Reference: bach_reference_intervals.json\n",
      "LLM Generated: llm_bach_intervals.json\n",
      "Loaded Bach reference data\n",
      "Loaded LLM generated data\n",
      "Data loaded: 2912 Bach intervals, 2065 LLM intervals\n",
      "\n",
      "1. STEPWISE MOTION ANALYSIS\n",
      "---------------------------------------------\n",
      "Stepwise Motion (±1,±2 semitones):\n",
      "   Bach: 43.3% (1260/2912)\n",
      "   LLM:  28.2% (582/2065)\n",
      "   Ratio: 0.65x Bach's rate\n",
      "   Similarity: 65.1%\n",
      "\n",
      "2. LEAP PATTERN ANALYSIS\n",
      "-----------------------------------\n",
      "Large Leaps (>3 semitones):\n",
      "   Bach: 20.1% (586/2912)\n",
      "   LLM:  44.1% (911/2065)\n",
      "   Ratio: 2.19x Bach's rate\n",
      "   Similarity: 0.0%\n",
      "\n",
      "3. MELODIC CONTOUR ANALYSIS\n",
      "----------------------------------------\n",
      "Direction Changes (melodic peaks/valleys):\n",
      "   Bach: 68.3% (1987 changes)\n",
      "   LLM:  47.8% (987 changes)\n",
      "   Ratio: 0.70x Bach's rate\n",
      "   Similarity: 70.1%\n",
      "\n",
      "4. BACH'S TOP INTERVAL REPRODUCTION\n",
      "----------------------------------------\n",
      "Bach's Top 5 Intervals vs LLM Reproduction:\n",
      "   1.  -2: Bach 14.4% -> LLM 16.4% = 86.0% similarity\n",
      "   2.  +2: Bach 10.5% -> LLM  4.2% = 40.1% similarity\n",
      "   3.  -1: Bach 10.0% -> LLM  5.3% = 53.0% similarity\n",
      "   4.  +1: Bach  8.4% -> LLM  2.3% = 27.5% similarity\n",
      "   5.  -3: Bach  4.7% -> LLM  5.0% = 93.0% similarity\n",
      "\n",
      "5. CHROMATIC CONTENT ANALYSIS\n",
      "----------------------------------------\n",
      "Chromatic Content (±1 semitone):\n",
      "   Bach: 18.4%\n",
      "   LLM:  7.6%\n",
      "   Ratio: 0.41x Bach's rate\n",
      "   Similarity: 41.3%\n",
      "\n",
      "6. LLM'S NON-BACH PATTERN ANALYSIS\n",
      "----------------------------------------\n",
      "LLM's top patterns Bach doesn't use:\n",
      "    +4: LLM 19.8% vs Bach  1.4%\n",
      "    +3: LLM 18.2% vs Bach  2.9%\n",
      "    -9: LLM  2.8% vs Bach  0.8%\n",
      "\n",
      "   Non-Bach contamination: 40.7%\n",
      "   Bach purity score: 59.3%\n",
      "\n",
      "AUTHENTICITY ASSESSMENT\n",
      "==================================================\n",
      "Individual Metric Scores:\n",
      "   Stepwise Motion Reproduction:  65.1% (weight: 0.3)\n",
      "   Top Interval Reproduction:  59.9% (weight: 0.3)\n",
      "   Leap Restraint           :   0.0% (weight: 0.2)\n",
      "   Contour Matching         :  70.1% (weight: 0.1)\n",
      "   Chromatic Reproduction   :  41.3% (weight: 0.1)\n",
      "\n",
      "Overall Authenticity Score: 48.6%\n",
      "MIXED: Some Bach elements but significant gaps\n",
      "\n",
      "COMPARISON:\n",
      "   Old (flawed) method: 82.4%\n",
      "   New method: 48.6%\n",
      "   Difference: +33.8%\n",
      "\n",
      "FINAL ASSESSMENT\n",
      "========================================\n",
      " 48.6% Bach authenticity\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import note_seq\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "import os\n",
    "\n",
    "def calculate_ratio_similarity(bach_value, llm_value):\n",
    "    \"\"\"\n",
    "    Calculate proper ratio-based similarity instead of difference-based.\n",
    "    Returns the proportion that LLM achieved relative to Bach (0-100%).\n",
    "    \"\"\"\n",
    "    if bach_value == 0 and llm_value == 0:\n",
    "        return 100.0  # Both zero = perfect match\n",
    "    elif bach_value == 0:\n",
    "        return 0.0    # Bach has none, LLM has some = no similarity\n",
    "    else:\n",
    "        # Calculate how much LLM achieved relative to Bach\n",
    "        ratio = llm_value / bach_value\n",
    "        # Cap at 100% (can't be more similar than perfect match)\n",
    "        # But if LLM exceeds Bach significantly, similarity decreases\n",
    "        if ratio <= 1.0:\n",
    "            return ratio * 100\n",
    "        else:\n",
    "            # Penalize overshooting Bach's pattern\n",
    "            return max(0, 100 - ((ratio - 1) * 100))\n",
    "\n",
    "def calculate_distribution_similarity(bach_dist, llm_dist, top_n=5):\n",
    "    \"\"\"\n",
    "    Calculate similarity based on how well LLM reproduces Bach's most important intervals.\n",
    "    \"\"\"\n",
    "    total_similarity = 0\n",
    "    bach_total = sum(bach_dist.values())\n",
    "    llm_total = sum(llm_dist.values())\n",
    "    \n",
    "    # Get Bach's top N most important patterns\n",
    "    bach_top = bach_dist.most_common(top_n)\n",
    "    \n",
    "    for interval, bach_count in bach_top:\n",
    "        bach_percentage = (bach_count / bach_total) * 100\n",
    "        llm_count = llm_dist.get(interval, 0)\n",
    "        llm_percentage = (llm_count / llm_total) * 100 if llm_total > 0 else 0\n",
    "        \n",
    "        reproduction_score = calculate_ratio_similarity(bach_percentage, llm_percentage)\n",
    "        total_similarity += reproduction_score\n",
    "    \n",
    "    return total_similarity / top_n\n",
    "\n",
    "def comprehensive_musical_analysis(bach_json='bach_reference_intervals.json', \n",
    "                                           llm_json='llm_bach_intervals.json', \n",
    "                                           bach_midi_folder=None, \n",
    "                                           llm_midi_folder=None):\n",
    "    \"\"\"\n",
    "    Comprehensive analysis using proper ratio-based similarity calculations.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"COMPREHENSIVE MUSICAL ANALYSIS\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Using ratio-based similarity calculations\")\n",
    "    print(f\"Bach Reference: {bach_json}\")\n",
    "    print(f\"LLM Generated: {llm_json}\")\n",
    "    \n",
    "    # Load interval data\n",
    "    try:\n",
    "        with open(bach_json, 'r') as f:\n",
    "            bach_data = json.load(f)\n",
    "        print(f\"Loaded Bach reference data\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading Bach data: {e}\")\n",
    "        return None\n",
    "        \n",
    "    try:\n",
    "        with open(llm_json, 'r') as f:\n",
    "            llm_data = json.load(f)\n",
    "        print(f\"Loaded LLM generated data\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading LLM data: {e}\")\n",
    "        return None\n",
    "    \n",
    "    # Extract intervals\n",
    "    if isinstance(bach_data, list):\n",
    "        bach_intervals = bach_data\n",
    "    elif isinstance(bach_data, dict):\n",
    "        if 'intervals' in bach_data:\n",
    "            bach_intervals = bach_data['intervals']\n",
    "        elif 'interval_sequences' in bach_data:\n",
    "            bach_intervals = bach_data['interval_sequences']\n",
    "        else:\n",
    "            bach_intervals = []\n",
    "            for value in bach_data.values():\n",
    "                if isinstance(value, list):\n",
    "                    bach_intervals.extend(value)\n",
    "    \n",
    "    if isinstance(llm_data, list):\n",
    "        llm_intervals = llm_data\n",
    "    elif isinstance(llm_data, dict):\n",
    "        if 'intervals' in llm_data:\n",
    "            llm_intervals = llm_data['intervals']\n",
    "        elif 'interval_sequences' in llm_data:\n",
    "            llm_intervals = llm_data['interval_sequences']\n",
    "        else:\n",
    "            llm_intervals = []\n",
    "            for value in llm_data.values():\n",
    "                if isinstance(value, list):\n",
    "                    llm_intervals.extend(value)\n",
    "    \n",
    "    print(f\"Data loaded: {len(bach_intervals)} Bach intervals, {len(llm_intervals)} LLM intervals\")\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # Analysis 1: Stepwise Motion\n",
    "    print(\"\\n1. STEPWISE MOTION ANALYSIS\")\n",
    "    print(\"-\" * 45)\n",
    "    \n",
    "    bach_interval_dist = Counter(bach_intervals)\n",
    "    llm_interval_dist = Counter(llm_intervals)\n",
    "    \n",
    "    stepwise_intervals = [-2, -1, +1, +2]\n",
    "    bach_stepwise = sum(bach_interval_dist[i] for i in stepwise_intervals)\n",
    "    llm_stepwise = sum(llm_interval_dist[i] for i in stepwise_intervals)\n",
    "    \n",
    "    bach_stepwise_pct = (bach_stepwise / len(bach_intervals)) * 100\n",
    "    llm_stepwise_pct = (llm_stepwise / len(llm_intervals)) * 100\n",
    "    \n",
    "    stepwise_similarity = calculate_ratio_similarity(bach_stepwise_pct, llm_stepwise_pct)\n",
    "    \n",
    "    print(f\"Stepwise Motion (±1,±2 semitones):\")\n",
    "    print(f\"   Bach: {bach_stepwise_pct:.1f}% ({bach_stepwise}/{len(bach_intervals)})\")\n",
    "    print(f\"   LLM:  {llm_stepwise_pct:.1f}% ({llm_stepwise}/{len(llm_intervals)})\")\n",
    "    print(f\"   Ratio: {llm_stepwise_pct/bach_stepwise_pct:.2f}x Bach's rate\")\n",
    "    print(f\"   Similarity: {stepwise_similarity:.1f}%\")\n",
    "    \n",
    "    results['stepwise_analysis'] = {\n",
    "        'bach_stepwise_pct': bach_stepwise_pct,\n",
    "        'llm_stepwise_pct': llm_stepwise_pct,\n",
    "        'stepwise_similarity': stepwise_similarity,\n",
    "        'ratio_multiplier': llm_stepwise_pct / bach_stepwise_pct\n",
    "    }\n",
    "    \n",
    "    # Analysis 2: Leap Patterns\n",
    "    print(f\"\\n2. LEAP PATTERN ANALYSIS\")\n",
    "    print(\"-\" * 35)\n",
    "    \n",
    "    large_leaps = [i for i in range(-12, 13) if abs(i) > 3]\n",
    "    bach_leaps = sum(bach_interval_dist[i] for i in large_leaps)\n",
    "    llm_leaps = sum(llm_interval_dist[i] for i in large_leaps)\n",
    "    \n",
    "    bach_leap_pct = (bach_leaps / len(bach_intervals)) * 100\n",
    "    llm_leap_pct = (llm_leaps / len(llm_intervals)) * 100\n",
    "    \n",
    "    leap_similarity = calculate_ratio_similarity(bach_leap_pct, llm_leap_pct)\n",
    "    if llm_leap_pct > bach_leap_pct:\n",
    "        excess_penalty = (llm_leap_pct - bach_leap_pct) / bach_leap_pct\n",
    "        leap_similarity = max(0, leap_similarity - (excess_penalty * 50))\n",
    "    \n",
    "    print(f\"Large Leaps (>3 semitones):\")\n",
    "    print(f\"   Bach: {bach_leap_pct:.1f}% ({bach_leaps}/{len(bach_intervals)})\")\n",
    "    print(f\"   LLM:  {llm_leap_pct:.1f}% ({llm_leaps}/{len(llm_intervals)})\")\n",
    "    print(f\"   Ratio: {llm_leap_pct/bach_leap_pct:.2f}x Bach's rate\")\n",
    "    print(f\"   Similarity: {leap_similarity:.1f}%\")\n",
    "    \n",
    "    results['leap_analysis'] = {\n",
    "        'bach_leap_pct': bach_leap_pct,\n",
    "        'llm_leap_pct': llm_leap_pct,\n",
    "        'leap_similarity': leap_similarity,\n",
    "        'ratio_multiplier': llm_leap_pct / bach_leap_pct\n",
    "    }\n",
    "    \n",
    "    # Analysis 3: Direction Changes\n",
    "    print(f\"\\n3. MELODIC CONTOUR ANALYSIS\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    bach_direction_changes = count_direction_changes(bach_intervals)\n",
    "    llm_direction_changes = count_direction_changes(llm_intervals)\n",
    "    \n",
    "    bach_direction_pct = (bach_direction_changes / (len(bach_intervals)-1)) * 100 if len(bach_intervals) > 1 else 0\n",
    "    llm_direction_pct = (llm_direction_changes / (len(llm_intervals)-1)) * 100 if len(llm_intervals) > 1 else 0\n",
    "    \n",
    "    # CORRECTED CALCULATION\n",
    "    contour_similarity = calculate_ratio_similarity(bach_direction_pct, llm_direction_pct)\n",
    "    \n",
    "    print(f\"Direction Changes (melodic peaks/valleys):\")\n",
    "    print(f\"   Bach: {bach_direction_pct:.1f}% ({bach_direction_changes} changes)\")\n",
    "    print(f\"   LLM:  {llm_direction_pct:.1f}% ({llm_direction_changes} changes)\")\n",
    "    print(f\"   Ratio: {llm_direction_pct/bach_direction_pct:.2f}x Bach's rate\")\n",
    "    print(f\"   Similarity: {contour_similarity:.1f}%\")\n",
    "    \n",
    "    results['contour_analysis'] = {\n",
    "        'bach_direction_pct': bach_direction_pct,\n",
    "        'llm_direction_pct': llm_direction_pct,\n",
    "        'contour_similarity': contour_similarity,\n",
    "        'ratio_multiplier': llm_direction_pct / bach_direction_pct\n",
    "    }\n",
    "    \n",
    "    # Analysis 4: Top Interval Distribution Matching\n",
    "    print(f\"\\n4. BACH'S TOP INTERVAL REPRODUCTION\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # How well does LLM reproduce Bach's top patterns?\n",
    "    bach_top_5 = bach_interval_dist.most_common(5)\n",
    "    print(f\"Bach's Top 5 Intervals vs LLM Reproduction:\")\n",
    "    \n",
    "    interval_reproduction_scores = []\n",
    "    for i, (interval, bach_count) in enumerate(bach_top_5, 1):\n",
    "        bach_percentage = (bach_count / len(bach_intervals)) * 100\n",
    "        llm_count = llm_interval_dist.get(interval, 0)\n",
    "        llm_percentage = (llm_count / len(llm_intervals)) * 100 if len(llm_intervals) > 0 else 0\n",
    "        \n",
    "        reproduction_score = calculate_ratio_similarity(bach_percentage, llm_percentage)\n",
    "        interval_reproduction_scores.append(reproduction_score)\n",
    "        \n",
    "        print(f\"   {i}. {interval:+3d}: Bach {bach_percentage:4.1f}% -> LLM {llm_percentage:4.1f}% = {reproduction_score:4.1f}% similarity\")\n",
    "    \n",
    "    avg_interval_reproduction = sum(interval_reproduction_scores) / len(interval_reproduction_scores)\n",
    "    \n",
    "    results['interval_reproduction'] = {\n",
    "        'bach_top_intervals': bach_top_5,\n",
    "        'individual_scores': interval_reproduction_scores,\n",
    "        'avg_reproduction_score': avg_interval_reproduction\n",
    "    }\n",
    "    \n",
    "    # Analysis 5: Chromatic Content\n",
    "    print(f\"\\n5. CHROMATIC CONTENT ANALYSIS\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    chromatic = [-1, +1]\n",
    "    bach_chromatic = sum(1 for i in bach_intervals if i in chromatic)\n",
    "    llm_chromatic = sum(1 for i in llm_intervals if i in chromatic)\n",
    "    \n",
    "    bach_chromatic_pct = (bach_chromatic / len(bach_intervals)) * 100\n",
    "    llm_chromatic_pct = (llm_chromatic / len(llm_intervals)) * 100\n",
    "    \n",
    "    # CORRECTED CALCULATION\n",
    "    chromatic_similarity = calculate_ratio_similarity(bach_chromatic_pct, llm_chromatic_pct)\n",
    "    \n",
    "    print(f\"Chromatic Content (±1 semitone):\")\n",
    "    print(f\"   Bach: {bach_chromatic_pct:.1f}%\")\n",
    "    print(f\"   LLM:  {llm_chromatic_pct:.1f}%\")\n",
    "    print(f\"   Ratio: {llm_chromatic_pct/bach_chromatic_pct:.2f}x Bach's rate\")\n",
    "    print(f\"   Similarity: {chromatic_similarity:.1f}%\")\n",
    "    \n",
    "    results['chromatic_analysis'] = {\n",
    "        'bach_chromatic_pct': bach_chromatic_pct,\n",
    "        'llm_chromatic_pct': llm_chromatic_pct,\n",
    "        'chromatic_similarity': chromatic_similarity,\n",
    "        'ratio_multiplier': llm_chromatic_pct / bach_chromatic_pct\n",
    "    }\n",
    "    \n",
    "    # Analysis 6: LLM's Non-Bach Patterns\n",
    "    print(f\"\\n6. LLM'S NON-BACH PATTERN ANALYSIS\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Find LLM's most used patterns that Bach rarely/never used\n",
    "    llm_top_patterns = llm_interval_dist.most_common(10)\n",
    "    non_bach_patterns = []\n",
    "    \n",
    "    print(\"LLM's top patterns Bach doesn't use:\")\n",
    "    for interval, llm_count in llm_top_patterns:\n",
    "        bach_count = bach_interval_dist.get(interval, 0)\n",
    "        llm_pct = (llm_count / len(llm_intervals)) * 100\n",
    "        bach_pct = (bach_count / len(bach_intervals)) * 100\n",
    "        \n",
    "        # If LLM uses this pattern >3x more than Bach, it's \"non-Bach\"\n",
    "        if bach_count == 0 or (llm_pct / bach_pct) > 3:\n",
    "            non_bach_patterns.append((interval, llm_pct, bach_pct))\n",
    "    \n",
    "    for interval, llm_pct, bach_pct in non_bach_patterns[:5]:\n",
    "        print(f\"   {interval:+3d}: LLM {llm_pct:4.1f}% vs Bach {bach_pct:4.1f}%\")\n",
    "    \n",
    "    # Calculate contamination score\n",
    "    total_non_bach = sum(llm_pct for _, llm_pct, _ in non_bach_patterns)\n",
    "    contamination_score = max(0, 100 - total_non_bach)\n",
    "    \n",
    "    print(f\"\\n   Non-Bach contamination: {total_non_bach:.1f}%\")\n",
    "    print(f\"   Bach purity score: {contamination_score:.1f}%\")\n",
    "    \n",
    "    results['non_bach_analysis'] = {\n",
    "        'non_bach_patterns': non_bach_patterns,\n",
    "        'contamination_score': total_non_bach,\n",
    "        'purity_score': contamination_score\n",
    "    }\n",
    "    \n",
    "    # Overall Assessment\n",
    "    print(f\"\\nAUTHENTICITY ASSESSMENT\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Use only the most important metrics with proper weighting\n",
    "    core_metrics = [\n",
    "        ('Stepwise Motion Reproduction', results['stepwise_analysis']['stepwise_similarity'], 0.3),\n",
    "        ('Top Interval Reproduction', results['interval_reproduction']['avg_reproduction_score'], 0.3),\n",
    "        ('Leap Restraint', results['leap_analysis']['leap_similarity'], 0.2),\n",
    "        ('Contour Matching', results['contour_analysis']['contour_similarity'], 0.1),\n",
    "        ('Chromatic Reproduction', results['chromatic_analysis']['chromatic_similarity'], 0.1)\n",
    "    ]\n",
    "    \n",
    "    weighted_score = sum(score * weight for _, score, weight in core_metrics)\n",
    "    results['corrected_overall_score'] = weighted_score\n",
    "    \n",
    "    print(\"Individual Metric Scores:\")\n",
    "    for metric_name, score, weight in core_metrics:\n",
    "        print(f\"   {metric_name:<25}: {score:5.1f}% (weight: {weight:.1f})\")\n",
    "    \n",
    "    print(f\"\\nOverall Authenticity Score: {weighted_score:.1f}%\")\n",
    "    \n",
    "    if weighted_score > 75:\n",
    "        print(\"EXCELLENT: Strong Bach-style authenticity!\")\n",
    "    elif weighted_score > 60:\n",
    "        print(\"GOOD: Moderate Bach-style characteristics\")\n",
    "    elif weighted_score > 45:\n",
    "        print(\"MIXED: Some Bach elements but significant gaps\")\n",
    "    elif weighted_score > 30:\n",
    "        print(\"WEAK: Limited Bach-style authenticity\")\n",
    "    else:\n",
    "        print(\"POOR: Minimal Bach-style learning\")\n",
    "    \n",
    "    # Comparison with old method\n",
    "    old_method_scores = [84.9, 76.0, 79.6, 89.2]  # From your original results\n",
    "    old_average = sum(old_method_scores) / len(old_method_scores)\n",
    "    \n",
    "    print(f\"\\nCOMPARISON:\")\n",
    "    print(f\"   Old (flawed) method: {old_average:.1f}%\")\n",
    "    print(f\"   New method: {weighted_score:.1f}%\")\n",
    "    print(f\"   Difference: {old_average - weighted_score:+.1f}%\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "def count_direction_changes(intervals):\n",
    "    \"\"\"Count how often melody changes direction.\"\"\"\n",
    "    if len(intervals) < 2:\n",
    "        return 0\n",
    "    \n",
    "    direction_changes = 0\n",
    "    for i in range(1, len(intervals)):\n",
    "        prev_direction = 1 if intervals[i-1] > 0 else -1 if intervals[i-1] < 0 else 0\n",
    "        curr_direction = 1 if intervals[i] > 0 else -1 if intervals[i] < 0 else 0\n",
    "        \n",
    "        if prev_direction != 0 and curr_direction != 0 and prev_direction != curr_direction:\n",
    "            direction_changes += 1\n",
    "    \n",
    "    return direction_changes\n",
    "\n",
    "def run_comprehensive_analysis(bach_json='bach_reference_intervals.json', \n",
    "                                       llm_json='llm_bach_intervals.json'):\n",
    "    \"\"\"\n",
    "    Run the comprehensive analysis.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"RUNNING COMPREHENSIVE MUSICAL ANALYSIS\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Using proper ratio-based similarity calculations\")\n",
    "    print(\"Weighted scoring based on musical importance\")\n",
    "    print()\n",
    "    \n",
    "    results = comprehensive_musical_analysis(bach_json, llm_json)\n",
    "    \n",
    "    if results is None:\n",
    "        print(\"Analysis failed\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"\\nFINAL ASSESSMENT\")\n",
    "    print(\"=\" * 40)\n",
    "    print(f\" {results['corrected_overall_score']:.1f}% Bach authenticity\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "results = run_comprehensive_analysis()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831d3035-d99a-45fe-a608-8141f0d70448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATING COMPREHENSIVE VISUALIZATION SUITE\n",
      "==================================================\n",
      "1. Creating interval distribution comparison...\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "def visualize_interval_distributions(bach_json, llm_json):\n",
    "    \"\"\"Compare interval usage patterns between Bach and LLM.\"\"\"\n",
    "    \n",
    "    # Load data\n",
    "    with open(bach_json, 'r') as f:\n",
    "        bach_intervals = json.load(f)\n",
    "    with open(llm_json, 'r') as f:\n",
    "        llm_intervals = json.load(f)\n",
    "    \n",
    "    # Create frequency distributions\n",
    "    bach_freq = Counter(bach_intervals)\n",
    "    llm_freq = Counter(llm_intervals)\n",
    "    \n",
    "    # Get all intervals used by either\n",
    "    all_intervals = sorted(set(list(bach_freq.keys()) + list(llm_freq.keys())))\n",
    "    \n",
    "    # Create comparison data\n",
    "    bach_percentages = [(bach_freq[i] / len(bach_intervals)) * 100 for i in all_intervals]\n",
    "    llm_percentages = [(llm_freq[i] / len(llm_intervals)) * 100 for i in all_intervals]\n",
    "    \n",
    "    # Create visualization\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 10))\n",
    "    \n",
    "    # Plot 1: Side-by-side comparison - ONLY show significant intervals\n",
    "    significant_intervals = [i for i in all_intervals if bach_freq[i] > 10 or llm_freq[i] > 3]\n",
    "    sig_bach_pct = [(bach_freq[i] / len(bach_intervals)) * 100 for i in significant_intervals]\n",
    "    sig_llm_pct = [(llm_freq[i] / len(llm_intervals)) * 100 for i in significant_intervals]\n",
    "    \n",
    "    x_pos = np.arange(len(significant_intervals))\n",
    "    width = 0.35\n",
    "    \n",
    "    ax1.bar(x_pos - width/2, sig_bach_pct, width, label='Bach', alpha=0.8, color='blue')\n",
    "    ax1.bar(x_pos + width/2, sig_llm_pct, width, label='LLM', alpha=0.8, color='red')\n",
    "    \n",
    "    ax1.set_xlabel('Interval (semitones)')\n",
    "    ax1.set_ylabel('Usage Percentage (%)')\n",
    "    ax1.set_title('Interval Distribution Comparison: Bach vs LLM (Significant Intervals Only)')\n",
    "    ax1.set_xticks(x_pos)\n",
    "    ax1.set_xticklabels([f'{i:+d}' for i in significant_intervals], rotation=0, fontsize=12)\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 2: Focus on stepwise intervals\n",
    "    stepwise_intervals = [-5, -4, -3, -2, -1, 0, +1, +2, +3, +4, +5]\n",
    "    stepwise_bach = [bach_freq[i] / len(bach_intervals) * 100 for i in stepwise_intervals]\n",
    "    stepwise_llm = [llm_freq[i] / len(llm_intervals) * 100 for i in stepwise_intervals]\n",
    "    \n",
    "    x_step = np.arange(len(stepwise_intervals))\n",
    "    ax2.bar(x_step - width/2, stepwise_bach, width, label='Bach', alpha=0.8, color='blue')\n",
    "    ax2.bar(x_step + width/2, stepwise_llm, width, label='LLM', alpha=0.8, color='red')\n",
    "    \n",
    "    ax2.set_xlabel('Interval (semitones)')\n",
    "    ax2.set_ylabel('Usage Percentage (%)')\n",
    "    ax2.set_title('Stepwise Motion Comparison (±5 semitones)')\n",
    "    ax2.set_xticks(x_step)\n",
    "    ax2.set_xticklabels([f'{i:+d}' for i in stepwise_intervals])\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('interval_distribution_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Visualization saved as: interval_distribution_comparison.png\")\n",
    "\n",
    "def visualize_melodic_contours(bach_json, llm_json, sample_length=50):\n",
    "    \"\"\"Visualize actual melodic contours to see the difference.\"\"\"\n",
    "    \n",
    "    # Load data\n",
    "    with open(bach_json, 'r') as f:\n",
    "        bach_intervals = json.load(f)\n",
    "    with open(llm_json, 'r') as f:\n",
    "        llm_intervals = json.load(f)\n",
    "    \n",
    "    # Convert intervals back to pitch sequences for visualization\n",
    "    def intervals_to_pitches(intervals, start_pitch=60):\n",
    "        pitches = [start_pitch]\n",
    "        for interval in intervals:\n",
    "            pitches.append(pitches[-1] + interval)\n",
    "        return pitches\n",
    "    \n",
    "    # Get sample melodies\n",
    "    bach_sample = intervals_to_pitches(bach_intervals[:sample_length])\n",
    "    llm_sample = intervals_to_pitches(llm_intervals[:sample_length])\n",
    "    \n",
    "    # Create visualization\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 8))\n",
    "    \n",
    "    # Bach melody contour\n",
    "    ax1.plot(bach_sample, 'b-', linewidth=2, marker='o', markersize=3)\n",
    "    ax1.set_title(f'Bach Melodic Contour (First {sample_length} intervals)')\n",
    "    ax1.set_ylabel('MIDI Pitch')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.set_ylim(45, 85)  # Reasonable pitch range\n",
    "    \n",
    "    # LLM melody contour  \n",
    "    ax2.plot(llm_sample, 'r-', linewidth=2, marker='o', markersize=3)\n",
    "    ax2.set_title(f'LLM Melodic Contour (First {sample_length} intervals)')\n",
    "    ax2.set_xlabel('Note Position')\n",
    "    ax2.set_ylabel('MIDI Pitch')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    ax2.set_ylim(45, 85)  # Same range for comparison\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('melodic_contour_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Visualization saved as: melodic_contour_comparison.png\")\n",
    "\n",
    "\n",
    "\n",
    "def analyze_problematic_patterns(bach_json, llm_json):\n",
    "    \"\"\"Deep dive into why the LLM fails to match Bach.\"\"\"\n",
    "    \n",
    "    print(\"\\nDEEP DIVE: WHY LLM FAILS TO MATCH BACH\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Load data\n",
    "    with open(bach_json, 'r') as f:\n",
    "        bach_intervals = json.load(f)\n",
    "    with open(llm_json, 'r') as f:\n",
    "        llm_intervals = json.load(f)\n",
    "    \n",
    "    bach_freq = Counter(bach_intervals)\n",
    "    llm_freq = Counter(llm_intervals)\n",
    "    \n",
    "    print(\"INTERVALS LLM OVERUSES (vs Bach):\")\n",
    "    llm_only_intervals = []\n",
    "    for interval, llm_count in llm_freq.most_common(10):\n",
    "        llm_pct = (llm_count / len(llm_intervals)) * 100\n",
    "        bach_pct = (bach_freq[interval] / len(bach_intervals)) * 100\n",
    "        overuse = llm_pct - bach_pct\n",
    "        \n",
    "        if overuse > 5:  # More than 5% overuse\n",
    "            llm_only_intervals.append((interval, llm_pct, bach_pct, overuse))\n",
    "    \n",
    "    for interval, llm_pct, bach_pct, overuse in llm_only_intervals:\n",
    "        print(f\"    {interval:+3d}: LLM {llm_pct:5.1f}% vs Bach {bach_pct:4.1f}% (+{overuse:4.1f}% overuse)\")\n",
    "    \n",
    "    print(\"\\nINTERVALS LLM UNDERUSES (missing Bach patterns):\")\n",
    "    missing_patterns = []\n",
    "    for interval, bach_count in bach_freq.most_common(10):\n",
    "        bach_pct = (bach_count / len(bach_intervals)) * 100\n",
    "        llm_pct = (llm_freq[interval] / len(llm_intervals)) * 100\n",
    "        underuse = bach_pct - llm_pct\n",
    "        \n",
    "        if underuse > 5:  # More than 5% underuse\n",
    "            missing_patterns.append((interval, bach_pct, llm_pct, underuse))\n",
    "    \n",
    "    for interval, bach_pct, llm_pct, underuse in missing_patterns:\n",
    "        print(f\"    {interval:+3d}: Bach {bach_pct:5.1f}% vs LLM {llm_pct:4.1f}% (-{underuse:4.1f}% missing)\")\n",
    "    \n",
    "    return {\n",
    "        'overused_intervals': llm_only_intervals,\n",
    "        'underused_intervals': missing_patterns\n",
    "    }\n",
    "\n",
    "def create_all_visualizations(bach_json='bach_reference_intervals.json', llm_json='llm_bach_intervals.json'):\n",
    "    \"\"\"Create comprehensive visualization suite.\"\"\"\n",
    "    \n",
    "    print(\"CREATING COMPREHENSIVE VISUALIZATION SUITE\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # 1. Interval distribution comparison\n",
    "    print(\"1. Creating interval distribution comparison...\")\n",
    "    visualize_interval_distributions(bach_json, llm_json)\n",
    "    \n",
    "    # 2. Melodic contour comparison  \n",
    "    print(\"2. Creating melodic contour comparison...\")\n",
    "    visualize_melodic_contours(bach_json, llm_json)\n",
    "    \n",
    "\n",
    "    \n",
    "    # 3. Problem analysis\n",
    "    print(\"3. Analyzing problematic patterns...\")\n",
    "    problem_analysis = analyze_problematic_patterns(bach_json, llm_json)\n",
    "    \n",
    "    print(\"\\nVISUALIZATIONS CREATED:\")\n",
    "    print(\"   - interval_distribution_comparison.png\")\n",
    "    print(\"   - melodic_contour_comparison.png\")\n",
    "    \n",
    "    return problem_analysis\n",
    "\n",
    "def simple_interval_comparison(bach_json, llm_json):\n",
    "    \"\"\"Quick visual comparison of top intervals.\"\"\"\n",
    "    \n",
    "    # Load data\n",
    "    with open(bach_json, 'r') as f:\n",
    "        bach_intervals = json.load(f)\n",
    "    with open(llm_json, 'r') as f:\n",
    "        llm_intervals = json.load(f)\n",
    "    \n",
    "    bach_freq = Counter(bach_intervals)\n",
    "    llm_freq = Counter(llm_intervals)\n",
    "    \n",
    "    # Get top 10 intervals for each\n",
    "    bach_top = dict(bach_freq.most_common(10))\n",
    "    llm_top = dict(llm_freq.most_common(10))\n",
    "    \n",
    "    print(\"TOP 10 INTERVALS COMPARISON\")\n",
    "    print(\"=\" * 40)\n",
    "    print(\"Interval | Bach %  | LLM %   | Difference\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    all_top_intervals = sorted(set(list(bach_top.keys()) + list(llm_top.keys())))\n",
    "    \n",
    "    for interval in all_top_intervals:\n",
    "        bach_pct = (bach_top.get(interval, 0) / len(bach_intervals)) * 100\n",
    "        llm_pct = (llm_top.get(interval, 0) / len(llm_intervals)) * 100\n",
    "        diff = abs(bach_pct - llm_pct)\n",
    "        \n",
    "        print(f\"   {interval:+3d}   | {bach_pct:5.1f}% | {llm_pct:5.1f}% | {diff:5.1f}%\")\n",
    "\n",
    "\n",
    "create_all_visualizations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec83cee-31a5-46b9-99cf-4aa2b38233e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (llm-music)",
   "language": "python",
   "name": "llm-music"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
